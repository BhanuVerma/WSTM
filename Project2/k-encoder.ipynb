{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# CSE 6240 - Web Search & Text Mining - Project 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-Sparse Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# __author__ = 'Bhanu Verma', 'Nilaksh Das'\n",
    "# GTid = '903151012', '903129996'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import os\n",
    "import math\n",
    "from PIL import Image\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import tensorflow as tf\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "categoryArr = []\n",
    "animal_path = 'Data/Animal'\n",
    "person_path = 'Data/Person'\n",
    "\n",
    "# animal:0, fungus:1, geo:2, person:3, plant:4, sport:5\n",
    "categoryArr = [animal_path, person_path]\n",
    "\n",
    "size_tuple = (16,16)\n",
    "count = 0\n",
    "enco_bat_size = 50\n",
    "category_count_list = [0,0]\n",
    "\n",
    "for i in range(len(categoryArr)):\n",
    "    cat_dir = os.listdir(categoryArr[i])\n",
    "    category_count_list[i] += len(cat_dir)\n",
    "    \n",
    "animal_data = np.zeros(shape=(category_count_list[0],size_tuple[0]*size_tuple[1]))\n",
    "person_data = np.zeros(shape=(category_count_list[1],size_tuple[0]*size_tuple[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_image_data(path):\n",
    "    img = Image.open(path)\n",
    "    resized_img = img.resize(size_tuple)\n",
    "    img_arr = np.array(resized_img.convert('L')).flatten()\n",
    "    arr = img_arr\n",
    "    img.close()\n",
    "    \n",
    "    return arr            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_category_data(folder,data):\n",
    "    img_count = 0\n",
    "    category = os.listdir(folder)\n",
    "    for img_file in category:\n",
    "        path = folder + \"/\" + img_file\n",
    "        data[img_count] = get_image_data(path)\n",
    "        img_count += 1\n",
    "        if img_count % 200 == 0:\n",
    "            print('Number of images loaded from ', folder,\": \",img_count)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images loaded from  Data/Animal :  200\n",
      "Number of images loaded from  Data/Animal :  400\n",
      "Number of images loaded from  Data/Animal :  600\n",
      "Number of images loaded from  Data/Animal :  800\n",
      "Number of images loaded from  Data/Animal :  1000\n",
      "Number of images loaded from  Data/Animal :  1200\n",
      "Number of images loaded from  Data/Animal :  1400\n",
      "Number of images loaded from  Data/Person :  200\n",
      "Number of images loaded from  Data/Person :  400\n",
      "Number of images loaded from  Data/Person :  600\n",
      "Number of images loaded from  Data/Person :  800\n",
      "Number of images loaded from  Data/Person :  1000\n",
      "Number of images loaded from  Data/Person :  1200\n"
     ]
    }
   ],
   "source": [
    "animal_data = get_category_data(animal_path,animal_data)\n",
    "person_data = get_category_data(person_path,person_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Standard preprocessing of data\n",
    "scale = preprocessing.StandardScaler().fit(animal_data)\n",
    "scaled_animal_data = scale.transform(animal_data)\n",
    "\n",
    "scale = preprocessing.StandardScaler().fit(person_data)\n",
    "scaled_person_data = scale.transform(person_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(315, 256) (1256, 256)\n",
      "(249, 256) (993, 256)\n"
     ]
    }
   ],
   "source": [
    "# split data into training and testing data\n",
    "training_animal_data,testing_animal_data = train_test_split(scaled_animal_data, train_size=0.8, random_state=42)\n",
    "training_person_data,testing_person_data = train_test_split(scaled_person_data, train_size=0.8, random_state=42)\n",
    "\n",
    "print(testing_animal_data.shape,training_animal_data.shape)\n",
    "print(testing_person_data.shape,training_person_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def auto_encoder(training_data,number_iterations,learning_rate, errors, layers, sparsity_level, sparse=False):\n",
    "    top_k_layers = [int(sparsity_level * a) for a in layers]\n",
    "    sess = tf.Session()\n",
    "    start = 0\n",
    "    end = start + enco_bat_size\n",
    "    original_data_dim = training_data.shape[1]\n",
    "    with sess.as_default():\n",
    "        hidden_dim = layers[0]\n",
    "        input_dim = original_data_dim\n",
    "        x = tf.placeholder(\"float\", [None, input_dim])\n",
    "        W1 = tf.Variable(tf.random_uniform([input_dim, hidden_dim], -1.0 / math.sqrt(input_dim),\\\n",
    "                                          1.0 / math.sqrt(input_dim)))\n",
    "        b1 = tf.Variable(tf.zeros([hidden_dim]))\n",
    "        z1 = tf.nn.tanh(tf.matmul(x,W1) + b1)\n",
    "        \n",
    "        if sparse:\n",
    "            vals,indices = tf.nn.top_k(z1,top_k_layers[0])\n",
    "            k_largest = tf.reduce_min(vals,reduction_indices=[1])\n",
    "            k_largest = tf.cast(k_largest,tf.float32)\n",
    "            k_largest = tf.reshape(k_largest,[enco_bat_size,1])\n",
    "            z_new = tf.sub(z1,k_largest)\n",
    "            z_new = tf.nn.relu(z_new)\n",
    "        else:\n",
    "            z_new = z1\n",
    "        \n",
    "        input_dim = hidden_dim\n",
    "        hidden_dim = layers[1]\n",
    "        W2 = tf.Variable(tf.random_uniform([input_dim, hidden_dim], -1.0 / math.sqrt(input_dim),\\\n",
    "                                          1.0 / math.sqrt(input_dim)))\n",
    "        b2 = tf.Variable(tf.zeros([hidden_dim]))\n",
    "        z2 = tf.nn.tanh(tf.matmul(z1,W2) + b2)\n",
    "        \n",
    "        if sparse:\n",
    "            vals,indices = tf.nn.top_k(z2,top_k_layers[1])\n",
    "            k_largest = tf.reduce_min(vals,reduction_indices=[1])\n",
    "            k_largest = tf.cast(k_largest,tf.float32)\n",
    "            k_largest = tf.reshape(k_largest,[enco_bat_size,1])\n",
    "            z_new = tf.sub(z2,k_largest)\n",
    "            z_new = tf.nn.relu(z_new)\n",
    "        else:\n",
    "            z_new = z2\n",
    "        \n",
    "        Wdash2 = tf.transpose(W2)\n",
    "        bdash2 = tf.Variable(tf.zeros([layers[0]]))\n",
    "        reconstructed_x1 = tf.nn.tanh(tf.matmul(z_new,Wdash2) + bdash2)\n",
    "        \n",
    "        \n",
    "        Wdash1 = tf.transpose(W1)\n",
    "        bdash1 = tf.Variable(tf.zeros([original_data_dim]))\n",
    "        reconstructed_x = tf.nn.tanh(tf.matmul(reconstructed_x1,Wdash1) + bdash1)\n",
    "        \n",
    "\n",
    "        error = tf.reduce_mean(tf.square(x-reconstructed_x))\n",
    "        train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(error)\n",
    "        init = tf.initialize_all_variables()\n",
    "        sess.run(init)\n",
    "\n",
    "        for i in range(number_iterations): \n",
    "            batch_rows = np.random.choice(range(0,training_data.shape[0]), enco_bat_size, replace=False)\n",
    "            batch = training_data[batch_rows][:]\n",
    "            sess.run(train_step, feed_dict={x: batch})\n",
    "            e = sess.run(error, feed_dict={x: batch})\n",
    "            errors.append(e)\n",
    "        print(\"Autoencoder training done\")\n",
    "        w1_final = sess.run(W1)\n",
    "        b1_final = sess.run(b1)\n",
    "        w2_final = sess.run(W2)\n",
    "        b2_final = sess.run(b2)\n",
    "        w1_dash_final = sess.run(Wdash1)\n",
    "        b1_dash_final = sess.run(bdash1)\n",
    "        w2_dash_final = sess.run(Wdash2)\n",
    "        b2_dash_final = sess.run(bdash2)\n",
    "        ws = [w1_final,w2_final]\n",
    "        ws_dash = [w1_dash_final,w2_dash_final]\n",
    "        bs = [b1_final, b2_final]\n",
    "        bs_dash = [b1_dash_final,b2_dash_final]\n",
    "    return ws,ws_dash,bs,bs_dash\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_testing_error(testing_data,ws,bs,ws_dash,bs_dash,sparse=False):\n",
    "    top_k_layers = [int(sparsity_level * a) for a in layers]\n",
    "    errors = []\n",
    "    sess2 = tf.Session()\n",
    "    input_dim = testing_data.shape[1]\n",
    "    with sess2.as_default():\n",
    "        w1 = tf.Variable(ws[0],dtype=tf.float32)\n",
    "        b1 = tf.Variable(bs[0],dtype=tf.float32)\n",
    "        w2 = tf.Variable(ws[1],dtype=tf.float32)\n",
    "        b2 = tf.Variable(bs[1],dtype=tf.float32)\n",
    "\n",
    "        w1_dash = tf.Variable(ws_dash[0],dtype=tf.float32)\n",
    "        b1_dash = tf.Variable(bs_dash[0],dtype=tf.float32)\n",
    "        w2_dash = tf.Variable(ws_dash[1],dtype=tf.float32)\n",
    "        b2_dash = tf.Variable(bs_dash[1],dtype=tf.float32)\n",
    "        \n",
    "        x = tf.placeholder(\"float\", [None, input_dim])\n",
    "        z1 = tf.nn.tanh(tf.matmul(x,w1) + b1) \n",
    "        \n",
    "        if sparse:\n",
    "            vals,indices = tf.nn.top_k(z1,top_k_layers[0])\n",
    "            k_largest = tf.reduce_min(vals,reduction_indices=[1])\n",
    "            k_largest = tf.cast(k_largest,tf.float32)\n",
    "            k_largest = tf.reshape(k_largest,[1,1])\n",
    "            z_new = tf.sub(z1,k_largest)\n",
    "            z_new = tf.nn.relu(z_new)\n",
    "        else:\n",
    "            z_new = z1\n",
    "            \n",
    "        z2 = tf.nn.tanh(tf.matmul(z_new,w2) + b2) \n",
    "        if sparse:\n",
    "            vals,indices = tf.nn.top_k(z1,top_k_layers[1])\n",
    "            k_largest = tf.reduce_min(vals,reduction_indices=[1])\n",
    "            k_largest = tf.cast(k_largest,tf.float32)\n",
    "            k_largest = tf.reshape(k_largest,[1,1])\n",
    "            z_new = tf.sub(z2,k_largest)\n",
    "            z_new = tf.nn.relu(z_new)\n",
    "        else:\n",
    "            z_new = z2\n",
    "            \n",
    "        reconstructed_x1 = tf.nn.tanh(tf.matmul(z_new,w2_dash) + b2_dash)\n",
    "        reconstructed_x = tf.nn.tanh(tf.matmul(reconstructed_x1,w1_dash) + b1_dash)\n",
    "        error = tf.reduce_mean(tf.square(x-reconstructed_x))\n",
    "        init = tf.initialize_all_variables()\n",
    "        sess2.run(init)\n",
    "\n",
    "        for i in range(len(testing_data)): \n",
    "            batch = testing_data[i][:].reshape((1,input_dim))\n",
    "            e = sess2.run(error, feed_dict={x: batch})\n",
    "            errors.append(e)\n",
    "        print(\"Test error calculated\")\n",
    "        return np.mean(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9\n",
      "Autoencoder training done\n",
      "Test error calculated\n",
      "0.8\n",
      "Autoencoder training done\n",
      "Test error calculated\n"
     ]
    }
   ],
   "source": [
    "sparsity_levels = [0.9,0.8]\n",
    "errors_sparsity = []\n",
    "person_errors_sparse = []\n",
    "layers = [50,40]\n",
    "for sparsity_level in sparsity_levels:\n",
    "    print(sparsity_level)\n",
    "    errors = []\n",
    "    ws,ws_dash,bs,bs_dash = auto_encoder(training_person_data,10000,0.03,errors,layers,sparsity_level,True)\n",
    "    person_errors_sparse.append(errors)\n",
    "    test_error = get_testing_error(testing_person_data,ws,bs,ws_dash,bs_dash,sparse=True)\n",
    "    errors_sparsity.append(test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6246019, 0.59579772]\n"
     ]
    }
   ],
   "source": [
    "print(errors_sparsity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlMAAAE4CAYAAAB/mnbsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nodetdtCYMAMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x110d275f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.axis([0,len(errors_sparsity)-1,0.0,1.0])\n",
    "plt.plot(errors_sparsity,'ko-', color='blue', linewidth=1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(20,10))\n",
    "# plt.plot(person_errors,c='b')\n",
    "# plt.plot(person_errors_sparse,c='g')\n",
    "# plt.show()\n",
    "\n",
    "# print min(person_errors),min(person_errors_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "std_scale = preprocessing.StandardScaler().fit(errors)\n",
    "scaled_errors_train = std_scale.transform(errors)\n",
    "# std_scale = preprocessing.StandardScaler().fit(errors_test)\n",
    "# scaled_errors = std_scale.transform(errors_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(scaled_errors_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(e)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
