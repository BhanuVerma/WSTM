{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d35779e3f4d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn import preprocessing\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from matplotlib.pyplot import imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "folders = ['Data/Person']\n",
    "final_size = (10,10)\n",
    "count = 0\n",
    "enco_bat_size = 100\n",
    "fol_counts = [0,0]\n",
    "\n",
    "for i in range(2):\n",
    "    fdirs = os.listdir(folders[i])\n",
    "    fol_counts[i] += len(fdirs)\n",
    "\n",
    "original_data_person = np.zeros(shape=(fol_counts[0],final_size[0]*final_size[1]))\n",
    "original_data_sport = np.zeros(shape=(fol_counts[1],final_size[0]*final_size[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('./data/Person', ' ', 500)\n",
      "('./data/Person', ' ', 1000)\n",
      "('./data/Sport', ' ', 500)\n",
      "('./data/Sport', ' ', 1000)\n",
      "('./data/Sport', ' ', 1500)\n"
     ]
    }
   ],
   "source": [
    "def get_image_data(path):\n",
    "    img = Image.open(path)\n",
    "    arr = np.array(img.resize(final_size).convert('L')).flatten()\n",
    "    img.close()\n",
    "    return arr\n",
    "\n",
    "\n",
    "def get_fol_data(fol,data):\n",
    "    image = 0\n",
    "    fdirs = os.listdir(fol)\n",
    "    for fil in fdirs:\n",
    "        path = fol + \"/\" + fil\n",
    "        data[image] = get_image_data(path)\n",
    "        image = image+1\n",
    "        if image%500 == 0:\n",
    "            print(fol,\" \",image)\n",
    "    return data\n",
    "\n",
    "original_data_person = get_fol_data(folders[0],original_data_person)\n",
    "original_data_sport = get_fol_data(folders[1],original_data_sport)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((1242, 100), (1888, 100))\n"
     ]
    }
   ],
   "source": [
    "print(original_data_person.shape,original_data_sport.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "std_scale = preprocessing.StandardScaler().fit(original_data_person)\n",
    "scaled_original_data_person = std_scale.transform(original_data_person)\n",
    "\n",
    "std_scale = preprocessing.StandardScaler().fit(original_data_sport)\n",
    "scaled_original_data_sport = std_scale.transform(original_data_sport)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1. / 1. + np.exp(-x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(249, 100) (993, 100)\n",
      "(378, 100) (1510, 100)\n"
     ]
    }
   ],
   "source": [
    "boundary_person = int(0.8*scaled_original_data_person.shape[0])\n",
    "boundary_sport = int(0.8*scaled_original_data_sport.shape[0])\n",
    "\n",
    "training_data_person = scaled_original_data_person[0:boundary_person,:]\n",
    "testing_data_person = scaled_original_data_person[boundary_person:,:]\n",
    "\n",
    "training_data_sport = scaled_original_data_sport[0:boundary_sport,:]\n",
    "testing_data_sport = scaled_original_data_sport[boundary_sport:,:]\n",
    "\n",
    "print testing_data_person.shape,training_data_person.shape\n",
    "print testing_data_sport.shape,training_data_sport.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def auto_encoder(training_data,number_iterations,learning_rate, errors, layers, sparsity_level, sparse=False):\n",
    "    top_k_layers = [int(sparsity_level * a) for a in layers]\n",
    "    sess = tf.Session()\n",
    "    start = 0\n",
    "    end = start + enco_bat_size\n",
    "    original_data_dim = training_data.shape[1]\n",
    "    with sess.as_default():\n",
    "        hidden_dim = layers[0]\n",
    "        input_dim = original_data_dim\n",
    "        x = tf.placeholder(\"float\", [None, input_dim])\n",
    "        W1 = tf.Variable(tf.random_uniform([input_dim, hidden_dim], -1.0 / math.sqrt(input_dim),\\\n",
    "                                          1.0 / math.sqrt(input_dim)))\n",
    "        b1 = tf.Variable(tf.zeros([hidden_dim]))\n",
    "        z1 = tf.nn.tanh(tf.matmul(x,W1) + b1)\n",
    "        \n",
    "        if sparse:\n",
    "            vals,indices = tf.nn.top_k(z1,top_k_layers[0])\n",
    "            k_largest = tf.reduce_min(vals,reduction_indices=[1])\n",
    "            k_largest = tf.cast(k_largest,tf.float32)\n",
    "            k_largest = tf.reshape(k_largest,[enco_bat_size,1])\n",
    "            z_new = tf.sub(z1,k_largest)\n",
    "            z_new = tf.nn.relu(z_new)\n",
    "        else:\n",
    "            z_new = z1\n",
    "        \n",
    "        input_dim = hidden_dim\n",
    "        hidden_dim = layers[1]\n",
    "        W2 = tf.Variable(tf.random_uniform([input_dim, hidden_dim], -1.0 / math.sqrt(input_dim),\\\n",
    "                                          1.0 / math.sqrt(input_dim)))\n",
    "        b2 = tf.Variable(tf.zeros([hidden_dim]))\n",
    "        z2 = tf.nn.tanh(tf.matmul(z1,W2) + b2)\n",
    "        \n",
    "        if sparse:\n",
    "            vals,indices = tf.nn.top_k(z2,top_k_layers[1])\n",
    "            k_largest = tf.reduce_min(vals,reduction_indices=[1])\n",
    "            k_largest = tf.cast(k_largest,tf.float32)\n",
    "            k_largest = tf.reshape(k_largest,[enco_bat_size,1])\n",
    "            z_new = tf.sub(z2,k_largest)\n",
    "            z_new = tf.nn.relu(z_new)\n",
    "        else:\n",
    "            z_new = z2\n",
    "        \n",
    "        Wdash2 = tf.transpose(W2)\n",
    "        bdash2 = tf.Variable(tf.zeros([layers[0]]))\n",
    "        reconstructed_x1 = tf.nn.tanh(tf.matmul(z_new,Wdash2) + bdash2)\n",
    "        \n",
    "        \n",
    "        Wdash1 = tf.transpose(W1)\n",
    "        bdash1 = tf.Variable(tf.zeros([original_data_dim]))\n",
    "        reconstructed_x = tf.nn.tanh(tf.matmul(reconstructed_x1,Wdash1) + bdash1)\n",
    "        \n",
    "\n",
    "        error = tf.reduce_mean(tf.square(x-reconstructed_x))\n",
    "        train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(error)\n",
    "        init = tf.initialize_all_variables()\n",
    "        sess.run(init)\n",
    "\n",
    "        for i in range(number_iterations): \n",
    "            batch_rows = np.random.choice(range(0,training_data.shape[0]), enco_bat_size, replace=False)\n",
    "            batch = training_data[batch_rows][:]\n",
    "            sess.run(train_step, feed_dict={x: batch})\n",
    "            e = sess.run(error, feed_dict={x: batch})\n",
    "            errors.append(e)\n",
    "        print \"Autoencoder training done\"\n",
    "        w1_final = sess.run(W1)\n",
    "        b1_final = sess.run(b1)\n",
    "        w2_final = sess.run(W2)\n",
    "        b2_final = sess.run(b2)\n",
    "        w1_dash_final = sess.run(Wdash1)\n",
    "        b1_dash_final = sess.run(bdash1)\n",
    "        w2_dash_final = sess.run(Wdash2)\n",
    "        b2_dash_final = sess.run(bdash2)\n",
    "        ws = [w1_final,w2_final]\n",
    "        ws_dash = [w1_dash_final,w2_dash_final]\n",
    "        bs = [b1_final, b2_final]\n",
    "        bs_dash = [b1_dash_final,b2_dash_final]\n",
    "    return ws,ws_dash,bs,bs_dash\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_test_error(testing_data,ws,bs,ws_dash,bs_dash,sparse=False):\n",
    "    errors = []\n",
    "    sess2 = tf.Session()\n",
    "    input_dim = testing_data.shape[1]\n",
    "    with sess2.as_default():\n",
    "        w1 = tf.Variable(ws[0],dtype=tf.float32)\n",
    "        b1 = tf.Variable(bs[0],dtype=tf.float32)\n",
    "        w2 = tf.Variable(ws[1],dtype=tf.float32)\n",
    "        b2 = tf.Variable(bs[1],dtype=tf.float32)\n",
    "\n",
    "        w1_dash = tf.Variable(ws_dash[0],dtype=tf.float32)\n",
    "        b1_dash = tf.Variable(bs_dash[0],dtype=tf.float32)\n",
    "        w2_dash = tf.Variable(ws_dash[1],dtype=tf.float32)\n",
    "        b2_dash = tf.Variable(bs_dash[1],dtype=tf.float32)\n",
    "        \n",
    "        x = tf.placeholder(\"float\", [None, input_dim])\n",
    "        z1 = tf.nn.tanh(tf.matmul(x,w1) + b1) \n",
    "        \n",
    "        if sparse:\n",
    "            vals,indices = tf.nn.top_k(z1,top_k_layers[0])\n",
    "            k_largest = tf.reduce_min(vals,reduction_indices=[1])\n",
    "            k_largest = tf.cast(k_largest,tf.float32)\n",
    "            k_largest = tf.reshape(k_largest,[1,1])\n",
    "            z_new = tf.sub(z1,k_largest)\n",
    "            z_new = tf.nn.relu(z_new)\n",
    "        else:\n",
    "            z_new = z1\n",
    "            \n",
    "        z2 = tf.nn.tanh(tf.matmul(z_new,w2) + b2) \n",
    "        if sparse:\n",
    "            vals,indices = tf.nn.top_k(z1,top_k_layers[1])\n",
    "            k_largest = tf.reduce_min(vals,reduction_indices=[1])\n",
    "            k_largest = tf.cast(k_largest,tf.float32)\n",
    "            k_largest = tf.reshape(k_largest,[1,1])\n",
    "            z_new = tf.sub(z2,k_largest)\n",
    "            z_new = tf.nn.relu(z_new)\n",
    "        else:\n",
    "            z_new = z2\n",
    "            \n",
    "        reconstructed_x1 = tf.nn.tanh(tf.matmul(z_new,w2_dash) + b2_dash)\n",
    "        reconstructed_x = tf.nn.tanh(tf.matmul(reconstructed_x1,w1_dash) + b1_dash)\n",
    "        error = tf.reduce_mean(tf.square(x-reconstructed_x))\n",
    "        init = tf.initialize_all_variables()\n",
    "        sess2.run(init)\n",
    "\n",
    "        for i in range(len(testing_data)): \n",
    "            batch = testing_data[i][:].reshape((1,input_dim))\n",
    "            e = sess2.run(error, feed_dict={x: batch})\n",
    "            errors.append(e)\n",
    "        print \"Test error calculated\"\n",
    "        return np.mean(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# person_errors_train = []\n",
    "# ws,ws_dash,bs,bs_dash = auto_encoder(training_data_person,10000,0.03,person_errors,False)\n",
    "# print get_test_error(testing_data_person,ws,bs,ws_dash,bs_dash,sparse=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autoencoder training done\n",
      "Test error calculated\n",
      "Autoencoder training done\n",
      "Test error calculated\n",
      "Autoencoder training done\n",
      "Test error calculated\n",
      "Autoencoder training done\n",
      "Test error calculated\n",
      "Autoencoder training done\n",
      "Test error calculated\n",
      "Autoencoder training done\n",
      "Test error calculated\n",
      "Autoencoder training done\n",
      "Test error calculated\n",
      "Autoencoder training done\n",
      "Test error calculated\n",
      "Autoencoder training done\n",
      "Test error calculated\n"
     ]
    }
   ],
   "source": [
    "sparsity_levels = [0.9,0.8,0.7,0.6,0.5,0.4,0.3,0.2,0.1]\n",
    "errors_sparsity = []\n",
    "person_errors_sparse = []\n",
    "layers = [50,40]\n",
    "for sparsity_level in sparsity_levels:\n",
    "    errors = []\n",
    "    ws,ws_dash,bs,bs_dash = auto_encoder(training_data_person,10000,0.03,errors,layers,sparsity_level,True)\n",
    "    person_errors_sparse.append(errors)\n",
    "    test_error = get_test_error(testing_data_person,ws,bs,ws_dash,bs_dash,sparse=True)\n",
    "    errors_sparsity.append(test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlMAAAE4CAYAAAB/mnbsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f49f8e28090>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.axis([0,len(errors_sparsity)-1,0.0,1.0])\n",
    "plt.plot(errors_sparsity,'ko-', color='blue', linewidth=1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.57578313,\n",
       " 0.68344754,\n",
       " 0.58005559,\n",
       " 0.56254178,\n",
       " 0.59918457,\n",
       " 0.53991282,\n",
       " 0.6635384,\n",
       " 0.67937416,\n",
       " 0.9310469]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors_sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(20,10))\n",
    "# plt.plot(person_errors,c='b')\n",
    "# plt.plot(person_errors_sparse,c='g')\n",
    "# plt.show()\n",
    "\n",
    "# print min(person_errors),min(person_errors_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "std_scale = preprocessing.StandardScaler().fit(errors)\n",
    "scaled_errors_train = std_scale.transform(errors)\n",
    "# std_scale = preprocessing.StandardScaler().fit(errors_test)\n",
    "# scaled_errors = std_scale.transform(errors_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(scaled_errors_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(e)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
